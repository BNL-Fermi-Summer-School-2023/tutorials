{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0299f3af-0e57-4900-a83f-7f88c647a86b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c151f636-479a-40b0-b118-ffcd8c6ba9dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbcfafb-ad8c-4ef2-bbca-6e6283dec613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "plt.rc('axes', labelsize=12)\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f592eb-ad45-414f-acad-d6e2a51a5f26",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Regression and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecae89be-1442-43a9-aa9a-2cbff70f4ce5",
   "metadata": {},
   "source": [
    "Written by: [Matthew R. Carbone](https://www.bnl.gov/staff/mcarbone) | _Assistant Computational Scientist, Computational Science Initiative, Brookhaven National Laboratory_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eaf124-eb7b-41c7-b4f1-6792fd8fec3b",
   "metadata": {},
   "source": [
    "In this tutorial, we're going to go over the fundamentals of regression and classification, which are the two most common types of supervised learning. We will also discuss some of the best practices in machine learning, such as a train-validation-testing split. In regression problems, the objective is to learn a _continuous_ output. In classification problems, the objective is to learn a _discrete_ output. Here are some examples:\n",
    "- Predicting the cost of a house from its properties, such as square footage, number of bathrooms, etc. is a _regression_ problem.\n",
    "- Whether or not an image is of a cat or dog is a _classification_ problem.\n",
    "- Predicting the type of animal in an image is a _classification_ problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df42443-4fbb-47a6-bb3a-b96c92f5e675",
   "metadata": {},
   "source": [
    "**Learning objectives:**\n",
    "- Understand a variety of regression and classification algorithms.\n",
    "- Start to explore some of the fundamental concepts in machine learning, such as splitting data, overfitting, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e132cd22-31cc-4bb0-8823-a6d6c2e4704a",
   "metadata": {},
   "source": [
    "Regression and classification problems can be solved via a variety of different methods (or _models_). In this tutorial, we're going to go over the following types of models, which will form the backbone of your understanding for e.g. neural networks, and other types of machine learning, later on.\n",
    "- Linear regression\n",
    "- Polynomial regression\n",
    "- Logistic regression\n",
    "\n",
    "There are numerous [other types of models](https://www.listendata.com/2018/03/regression-analysis.html#Linear-Regression) which we simply won't have the time to dive into, but paradigmatically, the objective of all of these models is the same. Given some input, predict some output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40ab799-d376-4921-b58d-f9f9330ed9cc",
   "metadata": {},
   "source": [
    "## Ingredients for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2bfca4-511b-4233-b141-f390c5079fc4",
   "metadata": {},
   "source": [
    "There are a few \"ingredients\" to always consider when approaching a regression problem.\n",
    "- Your available data (\"dataset\")\n",
    "- Your choice of model (\"model\")\n",
    "- How you choose to fit the model to the data (\"optimizer\")\n",
    "- An indicator for how well your model fits the data (\"metric\"/\"criterion\")\n",
    "\n",
    "We will discuss all of these components today."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace206c5-00d1-4175-9ac3-23b7ee8a18e4",
   "metadata": {},
   "source": [
    "## Other resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edaf978-57f3-46fb-9824-432381d64793",
   "metadata": {},
   "source": [
    "- [Andrew Ng's flagship Coursera course on machine learning](https://www.coursera.org/specializations/machine-learning-introduction)\n",
    "- [Intro to regression analysis](https://towardsdatascience.com/introduction-to-regression-analysis-9151d8ac14b3)\n",
    "- [15 types of regression](https://www.listendata.com/2018/03/regression-analysis.html#Linear-Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e177bded-5e38-4c6b-a71e-52de42f930ee",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ec192d-61b3-4e78-aa70-e11392a8eebe",
   "metadata": {},
   "source": [
    "Let's begin with the simplest form of regression: that of fitting a line to data. We can recast this problem as learning a function $f(x) = y,$ where the form of $f$ is simply the familiar $f(x) = mx + b.$ Given a dataset $\\{x_i, y_i\\}$, we can \"learn\" the coefficients $m$ and $b$ that best model the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace82bd-f62b-4c7b-b424-502780c3795c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def linear_model(x, m, b):\n",
    "    return m * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d047f-0326-447c-a77d-876720ff1697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def linear_data_with_noise(seed=123, scale=0.5, N=100, slope=2.4, y_intercept=0.8):\n",
    "    np.random.seed(seed)\n",
    "    x = np.linspace(-1, 1, N)\n",
    "    y = linear_model(x, slope, y_intercept) + np.random.normal(scale=scale, size=(N,))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0075f0-3b09-4d0e-9969-2b3669baafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = linear_data_with_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfacd60-7e84-4ee5-9fca-486dc5a05990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3, 2))\n",
    "\n",
    "ax.scatter(x, y)\n",
    "ax.set_xlabel(\"$x$\")\n",
    "ax.set_ylabel(\"$y$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c30ce42-0f9e-4595-93c3-c8e7a905a590",
   "metadata": {},
   "source": [
    "Suppose we fix $m$ and $b$ to some values $m_0$ and $b_0$. We now have a model which is completely defined, and given some value for $x$, we can predict $y.$ But how do we know if these are good choices? We need to define a metric, or a measure of how well the model fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012648e-cbd8-4d5f-93ee-58d4b52052a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def criterion(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f98e2-bea8-44b6-a764-06e93989d155",
   "metadata": {},
   "source": [
    "Above, our `criterion` is called the average mean squared error. The square root of this is the \"root-mean-squared\" error, which you are likely familiar with. For the purposes of this example, it doesn't really matter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9630f25d-04a4-4354-80f4-dee6e36fae50",
   "metadata": {},
   "source": [
    "## Evaluating an arbitrary model using a \"random\" optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c5ba7c-598d-4d5d-872f-4bdbd6dd0588",
   "metadata": {},
   "source": [
    "We know what the ground truth slope `m` and y-intercept `b` actually are, but let's pretend we don't, and evaluate a set of linear models against the data that we have. We can take a bunch of values for `m0` (guesses for the slope) and `b0` (guesses for the y-intercept), create a linear model with those parameters, and evaluate those against the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41041931-7a83-48a8-89e1-8fd00da8de66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "m0 = np.random.random(size=100) * 6 - 3  # 100 random numbers between -3 and 3\n",
    "b0 = np.random.random(size=100)          # 100 random numbers between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb35b064-0388-473e-b7fc-7eef131bb705",
   "metadata": {},
   "source": [
    "Let's try every one of these combinations for `m0` and `b0`, and valuate the model against our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de26ed2-08b6-4303-b512-1be843f1837c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5ec25a-2c68-4164-a54e-bedeb0626e11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m0b0 = list(product(m0, b0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3011f10-4eb2-4ee5-914d-6ddb994874a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"m0\": [params[0] for params in m0b0],\n",
    "    \"b0\": [params[1] for params in m0b0],\n",
    "    \"criterion\": [criterion(y, linear_model(x, *params)) for params in m0b0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d401523c-ece0-448e-b5ff-a65eda1ab69f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746c23e-7fd0-4477-b073-dadff00f85ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "argmin = df[\"criterion\"].argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da02cd92-a4c4-42a3-baec-85dc446b985c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.iloc[argmin, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5d7ecc-4798-4ef0-90b8-8d9bf5b92df6",
   "metadata": {},
   "source": [
    "## ⚠️ Check your understanding/Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f64c98-7784-43a3-88b5-f98fccf243d8",
   "metadata": {},
   "source": [
    "What happened here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5799900-0acd-482e-9b50-0adcff693828",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b97fa7-324b-49d3-be75-ce65eebd160c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24793c5-bf7c-4607-ab64-9fba47660048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
