{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Problems when Training ML/AI Models (And how to solve them without losing your mind) \n",
    "\n",
    "A practical guide for practical python users"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poor Data Quality \n",
    "\n",
    "A ml/ai algorithm is only as good at the data you give it. \n",
    "If you give data that contains no meaningful information, you shouldn't be surprized when the algorithm can't get anything out of it. \n",
    "However, we've got a whole lot of tips to get around the problems. \n",
    "You'll also build up an intutition for how to get around these with practice. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data\n",
    "\n",
    "Not every piece of data is always recorded. \n",
    "If a question is optional on a survey, not everyone is going to anwser. \n",
    "Unfortunately, models tend to get a little angry with a NaN or inf in a dataset. \n",
    "There are two main approaches to dealing with it. \n",
    "\n",
    "#### Replace\n",
    "\n",
    "Sometimes you are working with a smaller dataset and every single row is important. \n",
    "In this case, just skipping a row that is incomplete can cause downstream problems. \n",
    "Then, you'll want to replace any NaN values. \n",
    "(This includes inf and -inf!)\n",
    "\n",
    "This takes a little bit of work to understand what your data is doing and what the best approach is, to avoid introducing accidental bias or accidentally teaching your model to be a NaN detector. \n",
    "The most common things to replace missing values with are either 0, or the mean of the column. \n",
    "Using the mean generally means it will not change the distribution of the data dramatically (especially if the number of missing values is small). \n",
    "When replacing a missing number with 0 though, it's important to understand why it was missing. \n",
    "It's easy to skew the dataset if you don't think about it, so make sure to look at the distributions of your data before and after you make changes. \n",
    "\n",
    "It is also very important not to make guesses on your label/y field. \n",
    "If you are missing this field for a piece of data, if you replace it, you're already makinga  decision on what you want the model to train for; so it's best to just discard these points. \n",
    "It's like seeing that you don't know if the car should have turned right or left on your trip, and just deciding that \"Eh, it's probably to the right\" and possibly ending up in Springfield, Manitoba instead of Springfield, Illinois. \n",
    "\n",
    "#### Remove\n",
    "\n",
    "This is the more common solution.\n",
    "If your dataset is large enough, you can just remove any rows (or columns) that are missing important data. \n",
    "It's important to cut down your dataset to just the features you are going to use in training before you do this step though, you could end up losing data that would have been fine. \n",
    "\n",
    "Remove a single row when it's missing a field that is required for your training, or remove a whole column when it's either unimportant (Run some correlation tests to see if this is the case!) or mostly empty. \n",
    "It is important to make sure you're not accidentally covering up a systematic bias when you do this though. \n",
    "Is there a reason this field is empty for a lot entries? \n",
    "Always make sure you understand what your data is actually saying before making modifications. \n",
    "Remember, modeling is a science not just a series of checkboxes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data\n",
    "size = 200\n",
    "data = np.random.default_rng().standard_normal(0, 1, size=size)\n",
    "remove_indices = np.random.default_rng().integers(0, size-1, size=size*.05) # remove 5% of the data\n",
    "\n",
    "data[remove_indices] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace\n",
    "# This is a normal distirbution (from the definition), but it's good to look at the distribution without NaNs before you pick a replacement value\n",
    "# Could be better to use a mode or median! \n",
    "\n",
    "data_replaced = data.fillna(data.mean())\n",
    "\n",
    "plt.histogram(data_replaced)\n",
    "plt.title(\"Data, replacing the missing values with the mean\")\n",
    "plt.show()\n",
    "\n",
    "# Let's see how we can bias the data here \n",
    "data_replaced_zeros = data.fillna(0)\n",
    "\n",
    "plt.histogram(data_replaced_zeros)\n",
    "plt.title(\"Data, replacing the missing values with 0\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove\n",
    "# This method is a little easier, and probably better with such a well behaved problem\n",
    "data_dropped = data.dropna()\n",
    "\n",
    "plt.histogram(data_dropped)\n",
    "plt.title(\"Data, NaN's removed\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy Data \n",
    "\n",
    "\"Noise\" is an over-general term that refers to the problem from having information that does not contribute to the signal you want to study. \n",
    "It can come from any number of sources; like instrumentation noise when the data was collected, incorrect data recording, the like. \n",
    "A little noise isn't a bad thing, it can prevent models from overfitting, but when noise is so overwhelming it dominates the data, that's where a problem sits. \n",
    "\n",
    "\n",
    "Solutions: \n",
    "* Identify and remove overly-noisy data. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data with outliers\n",
    "\n",
    "Similarly to noisy data, if your data collection included possible errorsn in collection, points far outside the expected range, this can skew your results. \n",
    "Most likely, you don't want to account for these sort of outliers, or they're incredibly rare and satistically unimportant, you can throw them out. \n",
    "\n",
    "It is important to consider these outliers before you make a blanket statement that they're not useful, they could hold a clue to a problem upstream in the data collection procress, but this is not often the case. \n",
    "Sometimes there are just outliers. \n",
    "\n",
    "In this case, statitics can take care of us. \n",
    "You can use the quartiles to indentify the points widely outside the distirbution, and follow the same logic as if you were removing an NaN value. \n",
    "We'll use `np.quartile`, but pandas as identical functionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 200\n",
    "data = np.random.default_rng().standard_normal(0, 1, size=size)\n",
    "remove_indices = np.random.default_rng().integers(0, size-1, size=size*.05) # remove 5% of the data\n",
    "\n",
    "data[remove_indices] = np.random.default_rng().standard_normal(1, 5, size=size*.05) # Replace it with something.... different \n",
    "\n",
    "plt.hist(data, bins=20)\n",
    "plt.show() #Wow \n",
    "\n",
    "# Remove those outliers. \n",
    "\n",
    "outliers = np.quantile(data, 0.99) # Take everything in the 99% quartile. A little outside what we expect\n",
    "\n",
    "# Now let's use some indexing to remove this from the dataset \n",
    "\n",
    "non_outliers = data[data!=outliers]\n",
    "plt.hist(non_outliers, bins=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inbalanced Data \n",
    "\n",
    "Because not everything is equally likely, often you get datasets that are not perfectly even. \n",
    "This can cause a problem in training ML algorithms, because the model with learn to cheat and figure out that it can always select class A if class A is 95% of the dataset, and still get 95% accuracy. \n",
    "This sort of problem is obvious in problems like outlier detection (ex, fraud prevention, rare event tagging), but present to a degree in most (if not all) classification tasks. \n",
    "\n",
    "There's two main ways to solve this: \n",
    "\n",
    "#### Selective Sampling \n",
    "Also called stratified sampling, this means sampling a larger class down to the size of the smaller class. \n",
    "This is an approach best done when the data is biased, but not enough that one of the classes is TINYYYY compared to the other. \n",
    "Remember, this does throw out data from the larger class, so make sure your sub-samble is still representive of the class as a whole. \n",
    "Generally a uniform sampling scheme will work well enough, but running some comparisons between your sub-sample and the whole class is good practice. \n",
    "\n",
    "#### Label Weighing\n",
    "This method is better for highly imbalanced problems.\n",
    "When you weight labels, it means that you apply more importance to the smaller class in the loss function. \n",
    "So, if you have a 100/10 split in classes, but weight them 1:10, the loss function will treat the loss from any of the smaller class with 10x the gravity as anything from the dominate class. \n",
    "Basically, you just make your loss REALLY care about the smaller class, comparitively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, class_weights): \n",
    "    pass \n",
    "\n",
    "slightly_imbalanced_data = \"\"\n",
    "\n",
    "very_unbalanced_data = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Variance in Scale\n",
    "\n",
    "When your variables correlate to real world parameters, they are often in different units and different scales. \n",
    "Imagine you are trying to train a model to predict the difference between a cookie recipe and a cake recipe. \n",
    "So you would have the amount of milk in a unit like liters, and flour in grams. \n",
    "This ends up asking for something like .15 liters of milk and 150 grams of flour. \n",
    "The model is going to understand these numbers very differently, so it may put a large amount of importance on a variable you don't really need it to. \n",
    "(To a model, the difference between .2 L and 1 L is still smaller than 150 g to 145g!\n",
    "It only sees the numbers and how they relate to the labels, not the real meaning of the number, no matter how much LLMs want you to think otherwise.) \n",
    "\n",
    "To fix this, we can scale the units (such converting liters in milliliters,) or normalizing each row to take values between 0 and 1. \n",
    "Because not every value in the world has units, in AI we generally take the later approach. \n",
    "We can also normalize (where we assume the data fits a normal distribution and scale using the mean and standard deviation of the dataset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-Of-Domain Data \n",
    "\n",
    "Non-Representive Data (or out-of-domain data) is the problem where the features you have between different inferences of your model are not the same. \n",
    "This is common when doing things like moving from simulation to non-simulation data, or when you gather new data to expand your training set. \n",
    "Unfortunately, this has no Easy fix.\n",
    "But, it's a whole field of study. \n",
    "Check out the wikipedia page for [Domain Adaptation](https://en.wikipedia.org/wiki/Domain_adaptation). \n",
    "\n",
    "You can see a near identical from incorrectly scaling your input data. \n",
    "\n",
    "If your original work was done on a PCA-transformed dataset, you'll need to use the same fit transform to fit your validation data or any other data you preform inference on.\n",
    "Same goes for scaling, normalization, you name it. \n",
    "If it's a transform applied to your training data, it has to be applied to further input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troubled Training \n",
    "train_x = \"\"\n",
    "train_y = \"\"\n",
    "\n",
    "val_x = \"\"\n",
    "val_y = \"\"\n",
    "\n",
    "train_x = \"\" # Do some transform to x\n",
    "\n",
    "model = \"\"\n",
    "model_preformance = \"\"\n",
    "\n",
    "model_validation_preformance = \"\"\n",
    "\n",
    "print(model_preformance)\n",
    "print(model_validation_preformance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correction \n",
    "train_x = \"\"\n",
    "train_y = \"\"\n",
    "\n",
    "val_x = \"\"\n",
    "val_y = \"\"\n",
    "\n",
    "# The transform is a single instance\n",
    "fit_transform = \"\"\n",
    "\n",
    "train_x = fit_transform(train_x)\n",
    "val_x = fit_transform(val_x)\n",
    "\n",
    "model = \"\"\n",
    "model_preformance = \"\"\n",
    "\n",
    "model_validation_preformance = \"\"\n",
    "\n",
    "print(model_preformance)\n",
    "print(model_validation_preformance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Problems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improper Loss Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Too high/too low learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding problems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-descriptive variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwriting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharing and Reproduciblity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
