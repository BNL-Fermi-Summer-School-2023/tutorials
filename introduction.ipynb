{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lovely introduction that is both polite and painfully trying to reach college age students who I don't think I'm older than but at this point. Am older than. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives \n",
    "\n",
    "By the end of this session you should know how to......\n",
    "\n",
    "* Open a notebook in colab (You are here!)\n",
    "* Use basic python commands and syntax\n",
    "* Download contents of a git repository\n",
    "* Set up a conda virtual envorinment\n",
    "* Download common libraries are useful for AI/ML\n",
    "* Make a function that opens another file "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Logic\n",
    "\n",
    "\n",
    "Like most things in computers, the logic in python is based on binaries. \n",
    "If you want the computer to do something, it needs binary yes/no instructions on what to execute.\n",
    "These are called \"boolans\" in coding (and a lot of other contexts). \n",
    "\n",
    "\n",
    "We use logical operators (==, >, <, in, not) to make boolan statements that to stear the code. \n",
    "To do something something with those statements, we then use loops.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### If/Else Loops \n",
    "\n",
    "`if` is a command in python to check a boolan.\n",
    "_if_ that statement is true, the code proceeds to do the thing in the loop. \n",
    "_if_ it's not, it goes to the next piece of code without iteracting with the contents of the loop. \n",
    "\n",
    "`else` and `elif` are the counterparts to `if`. \n",
    "_if_ the boolan given to the `if` is false, it doesn't execute the `if`. \n",
    "In that case, it goes onto the next statement. \n",
    "The `else` can be that next statement, which isn't executed by the `if`. It's basically a `if not`. \n",
    "\n",
    "`elif` is a way to add an extra condition to that `if not`. \n",
    "(Basically `if (not A) and (B)`). \n",
    "\n",
    "### For Loops\n",
    "\n",
    "`for` is a shortcut in python (and other langauges) to keep running until you run out of objects in an iterable (something you cna iterate/loop over).\n",
    "It's sort of like a $\\Sigma$ notation, but you not limited to only performing sums in that loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if a number is even\n",
    "number = 6\n",
    "if number%2 == 0: # modulus operator\n",
    "    print(\"This number is even!\")\n",
    "else: \n",
    "    print(\"This number is odd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing every number in a list\n",
    "for number in [1,2,3,4,5]: \n",
    "    print(number)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Checkpoint! \n",
    "\n",
    "If you've got the idea down, now is the time to check that. \n",
    "\n",
    "Below is the skeleton for a function (don't worry if the term is confusing, we'll explain that in a second) that make a list of numbers 1 to N. Write a function that: \n",
    "\n",
    "1. Checks if the number is odd or even \n",
    "2. Adds the even numbers \n",
    "3. Skips the odd numbers \n",
    "\n",
    "Execute the below cell to verify you've got the right results!\n",
    "\n",
    "(hint: If you're struggling, make sure the code is doing what you think it's doing by using a `print` statement on the variable you're unsure about.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_adder(n_digits=20): \n",
    "    \n",
    "    digit_list = [i+1 for i in range(n_digits)]\n",
    "    even_sum = 0 \n",
    "    for digit in \"\":\n",
    "        if '': \n",
    "            even_sum = \"\"\n",
    "        else: \n",
    "            ''\n",
    "\n",
    "    return even_sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert even_adder(20) == 110\n",
    "assert even_adder(12) == 42\n",
    "assert even_adder(4) == 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and operations\n",
    "In python, functions are just ways to executing the same code over different inputs. \n",
    "The same way $f(x,y)$ can give you 5 or 9, depending on what x and y you give f as an input, the same applies to functions. \n",
    "\n",
    "If you ever find an operation you will probably repeat at another point in your code, it's a good idea to put it in a function! \n",
    "\n",
    "To make a function, it needs to be defined (using `def`), it needs to take inputs (using `()`), and it can to return something (with `return`). \n",
    "This is hard to describe in words so there's some examples below. Hopefully that is more helpful. \n",
    "\n",
    "Functions can also be given defaults, by assigning the input when you write the function.\n",
    " This means when someone uses that function, they don't need to give that variable a value. \n",
    " It will just take that default. \n",
    " It's a nice shortcut if you have a lot of things going on in the code and don't want to replace the variables all the time, just sometimes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic examples\n",
    "\n",
    "def do_addition(x, y): \n",
    "    return x + y \n",
    "\n",
    "def open_file(file_path): \n",
    "    with open(file_path, 'r') as f: \n",
    "        opened_file = f.read()\n",
    "    return opened_file\n",
    "\n",
    "def tell_me_what_im_thinking_of(what_im_thinking_about, polite=False): \n",
    "    oracles_repsonse = f\"You are thinking about {what_im_thinking_about}.\"\n",
    "    if polite: \n",
    "        oracles_repsonse += \"Isn't that right, dear?\"\n",
    "\n",
    "    print(oracles_repsonse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(do_addition(1, 2))\n",
    "print(do_addition(6, 7))\n",
    "print(tell_me_what_im_thinking_of(\"A nice lunch\", polite=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Checkpoint! \n",
    "\n",
    "Below is a few lines of code that have a common operation. It's up to you to transform that in a function! \n",
    "\n",
    "The next cell has a few statements to make sure you've got the right anwser, try those out to check your work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing simple code is way harder than I thought..... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skeleton_function(): \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert skeleton_function() == 5 \n",
    "assert skeleton_function() == 7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Git\n",
    "\n",
    "`git` is the foundational software versioning tool. If you want to store code and keep track of versions of code, `git` is the tool to use.  `GitHub`, and its other (sightly less Microsoft-owned) counterparts such as `GitLab` are the fundemental to how modern code works, giving code a place to live. \n",
    "\n",
    "For our purposes, we'll be using `GitHub` to organize the code used for the learning sessions. If you are so inclined, you can also `fork` these tutorials and keep a copy for yourself! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the tutorials \n",
    "\n",
    "Assuming you haven't already, run the below cell to download the tutorials. \n",
    "\n",
    "Adding a `!` in front of a cell in a jupyter notebook indicated that you want to run it as a cli execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/BNL-Fermi-Summer-School-2023/tutorials "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up your local work as a git repository\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git init"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store your work by commiting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git add introduction.ipynb\n",
    "! git commit -m \"YOUR MESSAGE HERE!\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a virtual envoriment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a conda env \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda env [YOUR ENV NAME HERE]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a new package! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda activate [THAT SAME ENV NAME]\n",
    "! conda add numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common packages\n",
    "\n",
    "Beauty of python is that it has some of the broadest and complete package support in the business.\n",
    "There are several incredibly powerful packages ready for you to use for AI/ML/Data Science, so we'll introduce you to some of the big players. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy \n",
    "Numpy needs no introduction.\n",
    "It is THE matrix operation package.\n",
    "It has lovely data structures, and a powerful C based back end. \n",
    "If you need to do any mathematics beyond \"1+1\", Numpy is the go to. \n",
    "\n",
    "[Documentation is here](https://numpy.org/doc/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the package so we can use it in the code\n",
    "import numpy as np # The common alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task \n",
    "# Generate random data and verify that the std and mean is where they're supposed to be\n",
    "\n",
    "# first: Generate the distirbution \n",
    "# Reference the documentation if you don't know what these inputs mean or what the function requires: \n",
    "# https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html#numpy.random.normal \n",
    "\n",
    "distribution_size = 200\n",
    "normal_distribution = np.random.default_rng().normal(0, 0.5, distribution_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check we've got the right size! \n",
    "normal_distribution.shape #`shape` is a parameter of the distribution, so we don't need to call it with ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's check the distribution for the mean and the standard deviation (which should be almost as we defined them in how we called them)\n",
    "normal_distribution.std() # std and mean are functions, so they need to be called with ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_distribution.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus! \n",
    "# Add noise to that distirbution. \n",
    "# Check those stats! They should be pretty similar\n",
    "\n",
    "# When we say \"noise\", we mean some other distirbution that isn't perfect that can change the shape of the distirbution. \n",
    "# Let's try with a uniform distirbution - from here: https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.uniform.html#numpy.random.Generator.uniform\n",
    "\n",
    "noise_shape = \"?\"\n",
    "noise_lower_bound = \"?\"\n",
    "noise_upper_bound = \"?\"\n",
    "\n",
    "noise = np.random.default_rng().uniform(noise_lower_bound, noise_upper_bound, noise_shape)\n",
    "\n",
    "# To apply that to the original distribution, we need to do some array manitpulation \n",
    "# Looky here! https://numpy.org/doc/stable/reference/arrays.ndarray.html#arithmetic-matrix-multiplication-and-comparison-operations\n",
    "noisy_normal_distribution = \"?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check by making sure the std and mean are around the same as the original \n",
    "\n",
    "assert (noisy_normal_distribution.std() > normal_distribution.std() - .1) and (noisy_normal_distribution.std() < normal_distribution.std() + .1)\n",
    "assert (noisy_normal_distribution.mean() > normal_distribution.mean() - .1) and (noisy_normal_distribution.mean() < normal_distribution.mean() + .1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas \n",
    "Another data structure power player. \n",
    "Great for data views, slicing and taking control over your input data. \n",
    "It has nice, easy to play with tables, so you can easily describe your data and table subsets based on row contents. \n",
    "It also uses a C backend in some spots, so it's pretty dang quick where it counts. \n",
    "\n",
    "[Documentation is here]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # common alais! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task \n",
    "# Make a data frame full of new (random) data and run some statistics\n",
    "\n",
    "# Pandas can be constructed from a lot of different objects. \n",
    "# for this tutorial, we'll make a dictionary with numpy arrays in it\n",
    "# And transform that into an dataframe we can do operations on! \n",
    "\n",
    "dataframe_length = 20\n",
    "intial_values = {\n",
    "    \"uniform_distribution\": np.random.default_rng().uniform(-1, 1, size=dataframe_length), # The default low and high for random.uniform is 0,1 (But we can check that)\n",
    "    \"linear_space\": np.linspace(-1, 1, dataframe_length), # A non-random distribution of 0 to 1. linspace produces an evenly spaced array\n",
    "    \"guassian_noise\": np.random.default_rng().normal(size=dataframe_length) # default guassian centers as 0.\n",
    "}\n",
    "\n",
    "spaces_dataframe = pd.DataFrame(intial_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now run some stats on this! \n",
    "\n",
    "# to access a value in a dataframe, we use the column name as an indexer\n",
    "\n",
    "spaces_dataframe[\"linear_space\"].unique() # Shows us all the unique values. Good for categorical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also look at the full dataframe with .describe to see a lot of stats for all the columns\n",
    "\n",
    "spaces_dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also take a subset of the dataframe based on a specific value \n",
    "\n",
    "# Lets see what all the values that have a negative value in the linear_space column\n",
    "spaces_dataframe[spaces_dataframe['linear_space']<0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also, lets add a new column to the dataframe that's a combination of existing data \n",
    "\n",
    "spaces_dataframe['noisy_linspace'] = spaces_dataframe['linear_space'] + spaces_dataframe['guassian_noise']\n",
    "\n",
    "spaces_dataframe['noisy_linspace'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 - Save and re-load that data\n",
    "\n",
    "# It's also important to know how to save existing data, so you can use it later, or if you don't want to re-run how it was made\n",
    "# Let's drop this dataframe we just made into a csv (comma seperated values) and load it up again to make sure it's the same as it was before\n",
    "\n",
    "save_location = \"./example_dataframe.csv\" # needs the extension name \n",
    "spaces_dataframe.to_csv(save_location, index=False) # setting index=False gets rid of the pandas assigned index (generally saved as 'Unnamed: 0') that we don't need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And load it back in to make sure our values are the same! \n",
    "matrix_reloaded = pd.read_csv(save_location) \n",
    "\n",
    "# Look through all the columns make sure they're the same columns: \n",
    "assert matrix_reloaded.columns.all() == spaces_dataframe.columns.all()\n",
    "# and look at all the values in those columns \n",
    "for column in spaces_dataframe.columns: \n",
    "    assert matrix_reloaded[column].values.all() == spaces_dataframe[column].values.all() #.values changes the pandas.Series object into a numpy array; so it's easier to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your challenge. If you choose to take it. \n",
    "\n",
    "# Is to make a new dataframe \n",
    "# Show the std and mean of a random subset of it \n",
    "\n",
    "new_dataframe = pd.DataFrame() \n",
    "\n",
    "new_dataframe[\"?\"] = \"?\" # construsting the df by adding columns one by one\n",
    "new_dataframe[\"?_2\"] = \"?\"\n",
    "\n",
    "selected_index = '?'\n",
    "\n",
    "subset_dataframe = new_dataframe[new_dataframe.index in \"?\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_dataframe.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Learn \n",
    "\n",
    "Scikit has some of the best off-the-shelf ML algorithms. \n",
    "It's very easy to use and full of useful diagonistics that help both beginers and seasoned practioners. \n",
    "\n",
    "Largely, it's split into classification (which is which) and regression (how much is that) tasks. \n",
    "If there is an ML algorithm you want to use, Scikit is the first place to look. \n",
    "\n",
    "[Documentation is here]()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we'll use the [Iris Classification dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris), and try to write an algorithm that splits them into their defined classes. \n",
    "First, we'll look at the classes, and then use a [Decision Tree]() to try to split them up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import everything we'll need here \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_features, iris_labels = load_iris(return_X_y=True, as_frame=True) \n",
    "# This is automatically split in labels (thing we want to get out of the model), and features (thing the model uses to learn)\n",
    "iris_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at our possible classes: \n",
    "iris_labels.unique() # Just numbers huh? \n",
    "\n",
    "# If you look at the documentation, you can see this corresponds to 'setosa', 'versicolor', and 'virginica'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we start training, let's make sure the model won't know the anwsers to the questions we're asking it to see how well it did. \n",
    "# We'll reserve a test set to make sure the model can't cheat\n",
    "\n",
    "feature_train, feature_test, label_train, label_test =  train_test_split(iris_features, iris_labels, test_size=.25) # Take 75% of the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we get to use the classifier \n",
    "tree = DecisionTreeClassifier().fit(feature_train, label_train) # trees are pretty simply so they're VERY fast to train \n",
    "\n",
    "# Let's see how good it is\n",
    "tree_predictions = tree.predict(feature_test)\n",
    "accuracy_score(label_test, tree_predictions) # Not bad!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try a regression task. \n",
    "For this, I'm going to ask you to load up the `diabetes` dataset from sklearn, and pick a regression algorithm to run on it. \n",
    "You'll need to do a little data-preprocessing before hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import your packages \n",
    "from sklearn.datasets import \"?\" # Find the dataset\n",
    "\n",
    "from sklearn.\"?\" import \"?\" # Pick your algorithm\n",
    "\n",
    "from sklearn.metrics import r2_score # evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = \"?\"\n",
    "features_train, features_test, labels_train, labels_test = \"?\"\n",
    "model = \"?\".fit(\"?\")\n",
    "prediction = model.predict(\"?\")\n",
    "\n",
    "r2_score(\"?\", prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib \n",
    "\n",
    "Now that we have a ton of packages to handle data, the little animal brain we have needs something to look at. \n",
    "Matplotlib is the best shot at that.\n",
    "It's the most wildly used plotting and visualizations package out there. \n",
    "This little introduction will only scratch the surface as to what it can do. \n",
    "\n",
    "[Here is the documentation](https://matplotlib.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task\n",
    "# Plot a normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot TWO distributions. On the same plot! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot your data from the sklearn example! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open an outside datasource\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "\n",
    "Let's grab some data from the [UCI ML Repository](https://archive.ics.uci.edu/ml/index.php )! \n",
    "It's a fantastic resource for toy datasets to test your skills on. \n",
    "\n",
    "For this example. Lets use the BEANS dataset. \n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Dry+Bean+Dataset \n",
    "\n",
    "To get the link to the zip, click the \"Dataset Folder\" link, and copy the link for the dataset zip.\n",
    "\n",
    "We're going to use `curl` to download the data to a specific path. \n",
    "[Documentation for `curl` can be found here.](https://curl.se/docs/manual.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "! curl https://archive.ics.uci.edu/ml/machine-learning-databases/00602/DryBeanDataset.zip --output \"DryBeanDataset.zip\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write something that opens the data! \n",
    "\n",
    "This stuff is in a zip, which makes it pretty hard to read in. \n",
    "Let's unzip it with another command line tool, `unzip`. \n",
    "\n",
    "Then, we'll have a file to work with. \n",
    "The file with data is actually a excel file, but we can work with that as well. \n",
    "[Pandas has a excel reader.](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip \"DryBeanDataset.zip\" -d \"./DryBeanDataset/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maggiev-local/miniforge3/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/maggiev-local/miniforge3\n",
      "\n",
      "  added / updated specs:\n",
      "    - openpyxl\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    et_xmlfile-1.1.0           |     pyhd8ed1ab_0          10 KB  conda-forge\n",
      "    openpyxl-3.1.2             |   py39h0f82c59_0         535 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         546 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  et_xmlfile         conda-forge/noarch::et_xmlfile-1.1.0-pyhd8ed1ab_0 None\n",
      "  openpyxl           conda-forge/osx-arm64::openpyxl-3.1.2-py39h0f82c59_0 None\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "openpyxl-3.1.2       | 535 KB    | ##################################### | 100% \n",
      "et_xmlfile-1.1.0     | 10 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Retrieving notices: ...working... done\n"
     ]
    }
   ],
   "source": [
    "! conda install -y openpyxl # You need to add openpyxl to your envoriment to use read_excel. The -y tag makes sure you don't need to confirm any installs\n",
    "\n",
    "# After you install something, and it doesn't show up, you need to restart your kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28395</td>\n",
       "      <td>610.291</td>\n",
       "      <td>208.178117</td>\n",
       "      <td>173.888747</td>\n",
       "      <td>1.197191</td>\n",
       "      <td>0.549812</td>\n",
       "      <td>28715</td>\n",
       "      <td>190.141097</td>\n",
       "      <td>0.763923</td>\n",
       "      <td>0.988856</td>\n",
       "      <td>0.958027</td>\n",
       "      <td>0.913358</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.834222</td>\n",
       "      <td>0.998724</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28734</td>\n",
       "      <td>638.018</td>\n",
       "      <td>200.524796</td>\n",
       "      <td>182.734419</td>\n",
       "      <td>1.097356</td>\n",
       "      <td>0.411785</td>\n",
       "      <td>29172</td>\n",
       "      <td>191.272750</td>\n",
       "      <td>0.783968</td>\n",
       "      <td>0.984986</td>\n",
       "      <td>0.887034</td>\n",
       "      <td>0.953861</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.909851</td>\n",
       "      <td>0.998430</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29380</td>\n",
       "      <td>624.110</td>\n",
       "      <td>212.826130</td>\n",
       "      <td>175.931143</td>\n",
       "      <td>1.209713</td>\n",
       "      <td>0.562727</td>\n",
       "      <td>29690</td>\n",
       "      <td>193.410904</td>\n",
       "      <td>0.778113</td>\n",
       "      <td>0.989559</td>\n",
       "      <td>0.947849</td>\n",
       "      <td>0.908774</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30008</td>\n",
       "      <td>645.884</td>\n",
       "      <td>210.557999</td>\n",
       "      <td>182.516516</td>\n",
       "      <td>1.153638</td>\n",
       "      <td>0.498616</td>\n",
       "      <td>30724</td>\n",
       "      <td>195.467062</td>\n",
       "      <td>0.782681</td>\n",
       "      <td>0.976696</td>\n",
       "      <td>0.903936</td>\n",
       "      <td>0.928329</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.861794</td>\n",
       "      <td>0.994199</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30140</td>\n",
       "      <td>620.134</td>\n",
       "      <td>201.847882</td>\n",
       "      <td>190.279279</td>\n",
       "      <td>1.060798</td>\n",
       "      <td>0.333680</td>\n",
       "      <td>30417</td>\n",
       "      <td>195.896503</td>\n",
       "      <td>0.773098</td>\n",
       "      <td>0.990893</td>\n",
       "      <td>0.984877</td>\n",
       "      <td>0.970516</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.941900</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
       "0  28395    610.291       208.178117       173.888747      1.197191   \n",
       "1  28734    638.018       200.524796       182.734419      1.097356   \n",
       "2  29380    624.110       212.826130       175.931143      1.209713   \n",
       "3  30008    645.884       210.557999       182.516516      1.153638   \n",
       "4  30140    620.134       201.847882       190.279279      1.060798   \n",
       "\n",
       "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
       "0      0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
       "1      0.411785       29172     191.272750  0.783968  0.984986   0.887034   \n",
       "2      0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n",
       "3      0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n",
       "4      0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n",
       "\n",
       "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  Class  \n",
       "0     0.913358      0.007332      0.003147      0.834222      0.998724  SEKER  \n",
       "1     0.953861      0.006979      0.003564      0.909851      0.998430  SEKER  \n",
       "2     0.908774      0.007244      0.003048      0.825871      0.999066  SEKER  \n",
       "3     0.928329      0.007017      0.003215      0.861794      0.994199  SEKER  \n",
       "4     0.970516      0.006697      0.003665      0.941900      0.999166  SEKER  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beans = pd.read_excel(\"./DryBeanDataset/DryBeanDataset/Dry_Bean_Dataset.xlsx\", engine='openpyxl')\n",
    "# use .head() to see the first 5 row \n",
    "beans.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Check \n",
    "\n",
    "Install the package [](), and see what version it is. \n",
    "\n",
    "Do Something with it. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge \n",
    "\n",
    "Use scikit learn to train a classifier to seperate out a UCI dataset into its classes. \n",
    "Visualize the data beforehand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skeleton code that does that. \n",
    "# fill in the blanks stuff "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6819b24f866a1aa258d04ed020a776a62b2936ca77337fe434989dfb9c603cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
